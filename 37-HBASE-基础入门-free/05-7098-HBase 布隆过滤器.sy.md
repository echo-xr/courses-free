---
show: step
version: 1.0
enable_checker: true
---

# HBase 布隆过滤器

## 实验介绍

学习 HBase 布隆过滤器。

#### 知识点

- 哈希
- 布隆过滤器
- HBase 中的布隆过滤器

## 哈希

哈希函数是计算机领域特别是在密码学领域应用最广泛的算法之一，哈希表是数据结构中应用最广泛的结构之一，这一节实验，我们将带领大家来了解哈希函数，了解哈希表。

本节实验包括以下 3 小节实验：

1. 哈希函数

2. 哈希表

3. 哈希函数在大数据中应用

### 哈希函数

#### 哈希函数的性质

哈希函数又名散列函数，对于经典哈希函数来说，它具有以下 5 点性质：

- 输入域无穷大

- 输出域有穷尽

- 输入一样输出肯定一样

- 当输入不一样输出也可能一样（哈希碰撞）

- 不同输入会均匀分布在输出域上（哈希函数的散列性）

这里对第 5 点做一些解释，例如输入域是 0-99 这一百个数字，而我们使用的哈希函数的输出域为 0,1,2，当我们将 0-99 这一百个数字通过该哈希函数，得到的返回值，0,1,2 数量都会接近 33 个，不会出现某个返回值数量特别多，而某个返回值特别少。

这里需要注意的是，对于哈希函数来说，有规律的输入并不能得到有规律的输出，例如十个 1Mb 的字符串，只有最后 1bytes 的内容不一样，在经过哈希函数后得到返回值千差万别，而不会有规律，所以它可以来打乱输入规律。

通常哈希函数的输出域都很大（相对于输入域很小），例如常见的 MD5（Message Digest Algorithm （中文名为消息摘要算法第五版））算法，它的输出域是 0 到 2^64-1，但是往往我们都会将哈希函数的返回值模上一个较小的数 m，让哈希函数的输出域缩减为 0 到 m-1.

#### 如何生成多个哈希函数

这里我们介绍一种快速生成多个哈希函数的方法。

假如你急需要 1000 个哈希函数，并且这 1000 个哈希函数都要求相互独立，不能有相关性。这时，错误的方法是去在网上寻找 1000 个哈希函数。我们可以通过一个哈希函数来生成这样的 1000 个独立的哈希函数。

假如，你有一个哈希函数 f，它的输出域是 2^64，也就是 16 字节的字符串，每个位置上是 16 进制的数字 0-9，a-f。

我们将这 16 字节的输出域分为两半，高八位，和低八位是相互独立的（这 16 位都相互独立）。这样，我们将高八位作为新的哈希函数 f1 的输出域，低八位作为新的哈希函数 f2 的输出域，得到两个新的哈希函数，它们之间相互独立。

故此可以通过以下算式得到 1000 个哈希函数：

```
f1+2*f2=f3
f1+3*f2=f4
f1+3*f2=f5
……
```

这里可以通过数学证明 f3 与 f4 及以后的哈希函数不相关，数学基础较好的同学可以查询相关资料，尝试证明，这里就不给出具体的证明了。

### 哈希表

#### 哈希表的经典结构

在数据结构中，哈希表最开始被描述成一个指针数组，数组中存入的每个元素是指向一个链表头部的指针。

我们知道，哈希表中存入的数据是 `key,value` 类型的，哈希表能够 `put(key,value)`，同样也能 `get(key,value)` 或者 `remove(key,value)`。当我们需要向哈希表中 put（插入记录）时，我们将 `key` 拿出，通过哈希函数计算 `hashcode`。假设我们预先留下的空间大小为 16，我们就需要将通过 `key` 计算出的 `hashcode` 模以 16，得到 0-15 之间的任意整数，然后我们将记录挂在相应位置的下面（包括 `key`，`value`）。

> 注意：位于哪个位置下只与 `key` 有关，与 `value` 无关。

例如我们要将下面这样一条记录插入哈希表中：

```bash
“shiyanlou”，666 # key是shiyanlou，value是666
```

首先我们通过哈希函数，计算 `shiyanlou` 的 `hashcode`，然后模以 16。假如我们得到的值是 6，哈希表会先去检查 6 位置下是否存在数据。如果有，检查该节点中的 `key` 是否等于 `shiyanlou`，如果等于，则将该节点中的 `value` 替换为 666；如果不等于，则在链表的最后新添加一个节点，保存我们的记录。

由于哈希函数的性质，得到的 `hashcode` 会均匀分布在输出域上，所以模以 16，得到的 0-15 之间的数目也相近。这就意味着我们哈希表每个位置下面的链表长度相近。

对于常见的几种数据结构来说，数组的特点是：容易寻址，但是插入和删除困难。而链表的特点是：寻址困难，但是插入和删除容易。而对于哈希表来说，它既容易寻址，同样插入和删除容易，这一点我们从它的数据结构中是显而易见的。

在实际哈希表应用中，它的查询速度近乎 `O(1)`，这是因为通过 `key` 计算 hashcode 的时间是常数项时间，而数组寻址的时间也是常数时间。在实际应用中，每个位置的链表长度不会太长，当到达一定长度后，哈希表会经历一次扩容，这就意味着遍历链表的时间也是常数时间。

所以，我们增删改查哈希表中的一条记录的时间可以默认为 `O(1)`。

### 哈希函数在大数据中的应用

例如，我们有一个 10TB 的大文件存在分布式文件系统上，存的是 100 亿行字符串，并且字符串无序排列，现在我们要统计该文件中重复的字符串。

假设，我们可以调用 100 台机器来计算该文件。

那么，现在我们需要怎样通过哈希函数来统计重复字符串呢。

首先，我们需要将这一百台机器分别从 0-99 标好号，然后我们在分布式文件系统中一行行读取文件（多台机器并行读取），通过哈希函数计算 `hashcode`，将计算出的 `hashcode` 模以 100，根据模出来的值，将该行存入对应的机器中。

根据哈希函数的性质，我们很容易看出，相同的字符串会存入相同的机器中。

然后我们就能并行 100 台机器，各自分别计算相应的数据，加快统计的速度。

> 注意：这 10TB 文件并不是均分成 100GB，分给 100 台机器，而是这 10TB 文件中不同字符串的种类，均分到 100 台机器中。如果还嫌单个机器处理的数据过大，可以按照同样的方法，在一台机器中并行多个进程，处理数据。

## 布隆过滤器

布隆过滤器（Bloom Filter）是 1970 由布隆提出的。通过一个很长的二进制向量于一系列随即哈希函数生成。

下面我们就将通过以下 2 小节来介绍布隆过滤器：

1. 原因与结构解析

2. 数学公式

### 原因与结构解析

首先，我们应当知道，hash 是内存中使用的经典数据结构。

当我们需要判读一个元素是否在一个集合当中时，我们可以用哈希表来判断。在集合较小的情况下，hash 是可行而且高效的。

然而数据量以 PT 计的大数据场景中，很多时候，hash 便力有未逮。这是因为在海量数据下 hash 要占据巨额内存空间，这远远超过我们能够提供的内存大小。

例如在黑名单过滤当中，我们有 100 亿的网站黑名单 `url` 需要过滤，假设一个 `url` 是 64bytes。如果我们用 hash 表来做，那么我们至少需要 6400 亿字节即 640G 的内存空间（实际所需空间还远大于此），空间消耗巨大，必须要多个服务器来同时分摊内存。

然而我们是否能用更加精简的结构来做这件事呢？布隆过滤器就是这样一个高度节省空间的结构，并且其时间也远超一般算法，但是布隆过滤器存在一定的失误率，例如在网页 URL 黑名单过滤中，布隆过滤器绝不会将黑名单中网页查错，但是有可能将正常的网页 URL 判定为黑名单当中的，它的失误可以说是宁可错杀，不可放过。不过布隆过滤器的失误率可以调节，下面我们会详细介绍。

布隆过滤器实际就是一种集合。假设我们有一个数组，它的长度为 L，从 0-（L-1）位置上，存储的不是一个字符串或者整数，而是一个 bit，这意味它的取值只能为 0 或 1.

例如我们实现如下的一个数组：

```
int[] array = new int[1000];
```

该数组中有 1000 个 `int` 类型的元素，而每一个 `int` 由有 4 个 `byte` 组成，一个 `byte` 又由 8 个 `bit` 组成，所以一个 `int` 就由 32 个 `bit` 所组成。

所以我们申请含 1000 整数类型的数组，它就包含 32000 个 `bit` 位。

但是我们如果想将第 20001 个 `bit` 位描黑，将其改为 1，我们需要怎样做呢。

首先我们的需要定位，这第 20001 个 `bit` 位于哪个整数，接着我们需要定位该 `bit` 位于该整数的第几个 `bit` 位。

```java
int index = 20001;
int intIndex = index/32;
int bitIndex = index%32;
```

然后我们就将其描黑：

```java
array[intIndex] =(array[intIndex] | (1 << bitIndex));
```

这段代码可能有些同学不能理解，下面我们详细解释一下。

我们的数组是 0-999 的整型数组，但是每个位置上实际保存的是 32 个 `bit`，我们的 `intIndex` 就是代表第几个整数，定位到 625，而 `bitIndex` 定位到第 625 个整数中的第几个 `bit`，为 1。

所以，我们需要描黑的位置是第 625 号元素的第 1 个 `bit`。

而 `(1 << bitIndex)` 代表将 1 左移到 1 位置，即是代表只有 1 位置为 1，而其他位置为零。就相当于获得了这样一串二进制数：

```
00000000 00000000 00000000 00000001
```

然后我们将这样的二进制数与 `array[indIndex]` 进行逻辑或运算，就能将第 625 号元素的第一个 `bit` 描黑变 1，最后我们将描黑后的元素赋值给 `array[indIndex]`，完成运算。

这里我们采用的是 `int` 类型的数组，如果我们想更加节省空间，我们就能创建 `long` 类型的数组，这样申请 1000 个数组空间，我们就能得到 64000 个 `bit`。

然后我们还能进一步扩展，将数组做成矩阵：

```
long[][] map = new long[1000][1000];
```

有了这些基础以后，我们如何设计黑名单问题呢？

假设我们已经有了一个拥有 `m` 个 `bit` 的数组，然后我们将一个 URL 通过哈希函数计算出 hashcode，然后 `hashcode%m` 将对应位置描黑。

然而这还不是真正的布隆过滤器，真正的布隆过滤器是通过多个哈希函数对一个 URL 进行计算，得到 `hashcode`，然后在对不同位置的 `bit` 进行描黑。

> 注意：布隆过滤器采用的多个哈希函数必须是相互独立的，前面我们已经介绍了如何通过一个哈希函数构造多个独立哈希函数的方法

当我们将一个 URL 通过 `n` 个哈希函数，得到 `hashcode`，模以 `m`，再将对应位置描黑之后。我们可以说该 URL 已经进入我们的布隆过滤器当中了。

接下来，我们将黑名单中所有 URL 都通过哈希函数，进入布隆过滤器中（布隆过滤器并不真正存储实际的 URL）。

对于一个新的 URL，我们要查询其是否在黑名单中，我们便通过同样的 `n` 个哈希函数，计算出 `n` 个位置，然后我们查询这 `n` 个位置是否都被描黑，如果都被描黑，我们就说该 URL 在黑名单当中。如果 `n` 个位置但凡有一个不为黑，我们就说该 URL 不在该黑名单中。

> 注意：我们的数组不应该过小，不然很可能数组中的大多数位置都被描黑，这很容易将正常的 URL 判定为不合法的，这也是布隆过滤器的失误率来源。

### 数学公式

通过上一小节的介绍，我们可以直观的感觉到，我们可以通过调整哈希函数 `n` 的大小以及数组 `m` 的大小来控制失误率。

事实确实如此，下面我们就介绍有有关哈希函数数量，数组大小，以及失误率的数学推论。

首先，我们要使用多少个哈希函数呢？

这一点只与我们黑名单中 URL 的数量及 `bit` 数组长度有关，而与单个 URL 的大小无关（哈希函数的输入域是无穷的）。它只要求我们的哈希函数能够接受 URL 这一参数类型。

而我们的数组或者矩阵的大小长度与什么有关呢？

它同样与我们黑名单中 URL 的数量有关，除此之外它还与我们能够接受的失误率有关。

下面我们给出有关公式：

![6-3.2-1](https://doc.shiyanlou.com/document-uid702660labid6674timestamp1528957217211.png/wm)

```
 #n为样本数量 p为预计的失误率
```

当我们的样本量为 100 亿，而我们预计的失误率为万分之一，根据这个公式我们便可以得到 m 为：

```
131571428572 bit
```

其单位为 `bit`，但我们实际要用的是 `byte`，所以还要除以 8，最后需要的空间为 23GB（向上取整）。

对比哈希表，原来我们需要 640GB，而现在只需要 23GB，大大节省了内存空间消耗。

而我们所需要的哈希函数的个数 k 的数学公式为：

```
k = ln2 * m/n #m为数组长度 n为样本数量 k向上取整
```

这里经过计算 n 为 13。

因为我们的 m 和 n 都经过了向上取整，所以我们的实际失误率会变得更低。失误率的计算公式为：

![6-3.2-3](https://doc.shiyanlou.com/document-uid702660labid6674timestamp1528957259045.png/wm)

```
#n为样本数量，m为数组长度，k为哈希函数个数
```

经过我们向上取整后，计算出来的实际失误率为十万分之六。

## HBase 中的布隆过滤器

布隆过滤器是 HBase 中的高级功能，它能够减少特定访问模式（get/scan）下的查询时间。不过由于这种模式增加了内存和存储的负担，所以被默认为关闭状态。

HBase 支持如下类型的布隆过滤器：

1、NONE 不使用布隆过滤器

2、ROW 行键使用布隆过滤器

3、ROWCOL 列键使用布隆过滤器

其中 ROWCOL 是粒度更细的模式。

### 4.1 原因

在介绍为什么 HBase 要引入布隆过滤器之前，我们先来了解一下 HBase 存储文件 HFile 的块索引机制

我们知道 HBase 的实际存储结构是 HFile，它是位于 hdfs 系统中的，也就是在磁盘中。而加载到内存中的数据存储在 MemStore 中，当 MemStore 中的数据达到一定数量时，它会将数据存入 HFile 中。

HFIle 是由一个个数据块与索引块组成，他们通常默认为 64KB。HBase 是通过块索引来访问这些数据块的。而索引是由每个数据块的第一行数据的 rowkey 组成的。当 HBase 打开一个 HFile 时，块索引信息会优先加载到内存当中。

然后 HBase 会通过这些块索引来查询数据。

但是块索引是相当粗粒度的，我们可以简单计算一下。假设一个行占 100bytes 的空间，所以一个数据块 64KB，所包含的行大概有：`(64 \* 1024)/100 = 655.53` ~= 700 行。而我们只能从索引给出的一个数据块的起始行开始查询。

如果用户随机查找一个行键，则这个行键很可能位于两个开始键（即索引）之间的位置。对于 HBase 来说，它判断这个行键是否真实存在的唯一方法就是加载这个数据块，并且扫描它是否包含这个键。

同时，还存在很多情况使得这种情况更加复杂。

对于一个应用来说，用户通常会以一定的速率进行更新数据，这就将导致内存中的数据被刷写到磁盘中，并且之后系统会将他们合并成更大的存储文件。在 HBase 的合并存储文件的时候，它仅仅会合并最近几个存储文件，直至合并的存储文件到达配置的最大大小。最终系统中会有很多的存储文件，所有的存储文件都是候选文件，其可能包含用户请求行键的单元格。如下图所示：

![6-4.1-1](https://doc.shiyanlou.com/document-uid702660labid6674timestamp1528969804609.png/wm)

我们可以看到，这些不同的文件都来着同一个列族，所以他们的行键分布类似。所以，虽然我们要查询更新的特定行只在某个或者某几个文件中，但是采用块索引方式，还是会覆盖整个行键范围。当块索引确定那些块可能含有某个行键后，regionServer 需要加载每一个块来检查该块中是否真的包含该行的单元格。

### 作用

从前一小节当中我们可以知道，当我们随机读 get 数据时，如果采用 HBase 的块索引机制，HBase 会加载很多块文件。如果采用布隆过滤器后，它能够准确判断该 HFile 的所有数据块中，是否含有我们查询的数据，从而大大减少不必要的块加载，从而增加 HBase 集群的吞吐率。

这里有几点细节：

#### 布隆过滤器的存储在哪？

对于 HBase 而言，当我们选择采用布隆过滤器之后，HBase 会在生成 StoreFile（HFile）时包含一份布隆过滤器结构的数据，称其为 MetaBlock；MetaBlock 与 DataBlock（真实的 KeyValue 数据）一起由 LRUBlockCache 维护。所以，开启 bloomfilter 会有一定的存储及内存 cache 开销。但是在大多数情况下，这些负担相对于布隆过滤器带来的好处是可以接受的。

#### 采用布隆过滤器后，HBase 如何 get 数据？

在读取数据时，HBase 会首先在布隆过滤器中查询，根据布隆过滤器的结果，再在 MemStore 中查询，最后再在对应的 HFile 中查询。

#### 采用 ROW 还是 ROWCOL 布隆过滤器？

这取决于用户的使用模式。如果用户只做行扫描，使用更加细粒度的行加列布隆过滤器不会有任何的帮助，这种场景就应该使用行级布隆过滤器。当用户不能批量更新特定的一行，并且最后的使用存储文件都含有改行的一部分时，行加列级的布隆过滤器更加有用。

例如：

**ROW 使用场景**

假设有 2 个 Hfile 文件 hf1 和 `hf2`：

`hf1` 包含 `kv1(r1 cf:q1 v)`、`kv2(r2 cf:q1 v)`

`hf2` 包含 `kv3(r3 cf:q1 v)`、`kv4(r4 cf:q1 v)`

如果设置了 CF 属性中的 bloomfilter（布隆过滤器）为 ROW，那么 get(r1) 时就会过滤 hf2，get(r3) 就会过滤 hf1 。

**ROWCOL 使用场景**

假设有 2 个 Hfile 文件 `hf1` 和 `hf2`：

`hf1` 包含 `kv1(r1 cf:q1 v)`、`kv2(r2 cf:q1 v)`

`hf2` 包含 `kv3(r1 cf:q2 v)`、`kv4(r2 cf:q2 v)`

如果设置了 `CF` 属性中的 `bloomfilter` 为 `ROW`，无论 `get(r1,q1)` 还是 `get(r1,q2)`，都会读取 `hf1+hf2`；而如果设置了 `CF` 属性中的 `bloomfilter` 为 `ROWCOL`，那么 `get(r1,q1)` 就会过滤 `hf2`，`get(r1,q2)` 就会过滤 `hf1`。

> 注意：ROW 和 ROWCOL 只是名字上有联系，但是 ROWCOL 并不是 ROW 的扩展，也不能取代 ROW。

## 实验总结

本次实验介绍了哈希函数、哈希表，由此引出了布隆过滤器，最后介绍了 HBase 的布隆过滤器。虽然本实验理论较多，没有动手操作的步骤，但是也对相应的概念举了例子，方便同学们深入的理解 HBase。所以，需要多次阅读本节实验，如果有什么不懂的地方，欢迎在留言区讨论。

## 参考资料

- http://hbase.apache.org/book.html
