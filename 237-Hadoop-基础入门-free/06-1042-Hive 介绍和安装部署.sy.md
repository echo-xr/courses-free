---
show: step
version: 1.0
enable_checker: true
---

# Hive 介绍和安装部署

## 实验介绍

本节实验将对 Hive 数据仓库进行介绍。

**环境说明**

> 注意：
>
> 本实验是对前述实验的延续，如果直接点“开始实验”进入则需要按实验 1 的方法配置并启动 hadoop。
>
> 实验使用的安装包、代码和数据均在 `/home/shiyanlou/install-pack` 目录下。

部署节点操作系统为 CentOS，防火墙和 SElinux 禁用，创建了一个 shiyanlou 用户并在系统根目录下创建 `/app` 目录，用于存放 Hadoop 等组件运行包。因为该目录用于安装 hadoop 等组件程序，用户对 shiyanlou 必须赋予 rwx 权限（一般做法是 root 用户在根目录下创建 `/app` 目录，并修改该目录拥有者为 shiyanlou(`chown –R shiyanlou:shiyanlou /app`)。

**Hadoop 搭建环境：**

- 虚拟机操作系统： CentOS 64 位，单核，1G 内存
- JDK：64 位
- Hadoop：1.1.2

#### 知识点

- Hive 介绍
- Hive 环境搭建
- Hive 常见问题解决

## Hive 介绍

Hive 是 Facebook 开发的构建于 Hadoop 集群之上的数据仓库应用，它提供了类似于 SQL 语法的 HQL 语句作为数据访问接口，这使得普通分析人员应用 Hadoop 的学习曲线变小，Hive 有如下特性：

- Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并使用 sql 语句转换为 MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。
- Hive 是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 的开发者来开发自定义的 Mapper 和 Reducer 处理内建的 Mapper 和 Reducer 无法完成的复杂分析工作。

### Hive 与关系数据库的区别

使用 Hive 的命令行接口很像操作关系数据库，但是 Hive 和关系数据库还是有很大的不同， Hive 与关系数据库的区别具体如下：

1. Hive 和关系数据库存储文件的系统不同，Hive 使用的是 Hadoop 的 HDFS（Hadoop 的分布式文件系统），关系数据库则是服务器本地的文件系统。
2. Hive 使用的计算模型是 MapReduce，而关系数据库则是自身的计算模型。
3. 关系数据库都是为实时查询的业务进行设计的，而 Hive 则是为海量数据做数据挖掘设计的，实时性很差；实时性的区别导致 Hive 的应用场景和关系数据库有很大的不同。
4. Hive 很容易扩展自己的存储能力和计算能力，这个是继承 Hadoop 的，而关系数据库在这个方面相比起来要差很多。

### Hive 架构

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943328371.png)

由上图可知，Hadoop 的 MapReduce 是 Hive 架构的根基。Hive 架构包括如下组件：CLI（command line interface）、JDBC/ODBC、Thrift Server、WEB GUI、Metastore 和 Driver(Complier、Optimizer 和 Executor)，这些组件分为两大类：服务端组件和客户端组件。

**服务端组件：**

- `Driver 组件`：该组件包括 Complier、Optimizer 和 Executor，它的作用是将 HiveQL（类 SQL）语句进行解析、编译优化，生成执行计划，然后调用底层的 MapReduce 计算框架。
- `Metastore 组件`：元数据服务组件，这个组件存储 Hive 的元数据，Hive 的元数据存储在关系数据库里，Hive 支持的关系数据库有 derby 和 mysql。元数据对于 Hive 十分重要，因此 Hive 支持把 metastore 服务独立出来，安装到远程的服务器集群里，从而解耦 Hive 服务和 metastore 服务，保证 Hive 运行的健壮性。
- `Thrift 服务`：Thrift 是 facebook 开发的一个软件框架，它用来进行可扩展且跨语言的服务的开发，Hive 集成了该服务，能让不同的编程语言调用 hive 的接口。

**客户端组件：**

- `CLI`：command line interface，命令行接口。
- `Thrift 客户端`：上面的架构图里没有写上 Thrift 客户端，但是 Hive 架构的许多客户端接口是建立在 Thrift 客户端之上，包括 JDBC 和 ODBC 接口。
- `WEBGUI`：Hive 客户端提供了一种通过网页的方式访问 hive 所提供的服务。这个接口对应 Hive 的 hwi 组件（hive web interface），使用前要启动 hwi 服务。

## 搭建 Hive 环境

本节我们将正式开始讲解搭建 Hive 环境，分步骤进行。

### 安装 MySql 数据库（实验环境中已经安装无需再次安装）

> 注意：由于实验环境中已经安装了 mysql 服务，后续安装步骤仅供参考，可直接跳转到 3.2 节继续学习；如果感兴趣可以参考 4.1 章节，删除 MySql 重新安装。

**下载 mysql 安装文件**

下载地址：`http://dev.mysql.com/downloads/mysql/#downloads` ，使用系统为 CentOS 选择 Red Hat Enterprise Linux/Oracle 系列，也可以在 /home/shiyanlou/install-pack 目录中找到这些安装包：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943354249.png/wm)

操作系统为 64 位，选择对应安装包进行下载：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943401281.png/wm)

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943411307.png/wm)

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943431269.png/wm)

下载在本地目录如下图：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943443294.png/wm)

**安装 mysql**

使用命令查看是否已经安装过 mysql：

```bash
sudo rpm -qa | grep -i mysql
```

可以看到如下图的所示：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943567729.png/wm)

说明之前安装了 mysql，可以参考 4.1 卸载旧的 mysql。

如果以前没有安装 mysql 则进入安装文件的目录，安装 mysql 服务端：

```bash
cd /home/shiyanlou/install-pack
sudo rpm -ivh MySQL-server-5.6.21-1.el6.x86_64.rpm
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433943587417.png/wm)

出现异常，通过分析缺少 libaio 依赖包，使用如下命令进行安装：

```bash
sudo yum install libaio
```

再次安装 mysql，并安装 mysql 客户端、mysql-devel：

```bash
sudo rpm -ivh MySQL-server-5.6.21-1.el6.x86_64.rpm
sudo rpm -ivh MySQL-client-5.6.21-1.el6.x86_64.rpm
sudo rpm -ivh MySQL-devel-5.6.21-1.el6.x86_64.rpm
```

**启动 mysql 服务**

通过下面查看 mysql 服务状态：

```bash
sudo service mysql status
```

如果 mysql 没有启动，通过如下命令进行启动：

```bash
sudo service mysql start
```

**设置 root 密码**

在 CentOS6.5 操作系统使用如下命令给 mysql 设置 root 密码时，出现如下错误：

```text
/usr/bin/mysqladmin -u root password 'root';

/usr/bin/mysqladmin: connect to server at 'localhost' failed
error: 'Access denied for user 'root'@'localhost' (using password: NO)'
```

可以进入安全模式设置 root 密码。

**（1）停止 mysql 服务**

使用如下命令停止 mysql 服务：

```bash
sudo service mysql stop
sudo service mysql status
```

**（2）跳过验证启动 mysql**

使用如下命令验证启动 mysql，由于 `&` 结尾是后台运行进程，运行该命令可以再打开命令窗口或者 Ctr+C 继续进行下步操作：

```bash
sudo mysqld_safe --skip-grant-tables &
sudo service mysql status
```

**（3）跳过验证启动 MySQL**

验证 mysql 服务已经在后台运行后，执行如下语句，其中后面三条命令是在 mysql 语句：

```sql
mysql -u root
mysql> use mysql;
mysql> update user set password = password('root') where user = 'root';
mysql> flush privileges;
mysql> quit;
```

**（4）跳过验证启动 MySQL**

重启 mysql 服务并查看状态

```bash
sudo service mysql restart
sudo service mysql status
```

**设置 Hive 用户**

进入 mysql 命令行，创建 hive 用户并赋予所有权限：（创建前请确认是否已有 hive 用户，若有则不需要创建）

```sql
mysql -uroot -proot
mysql> set password=password('root');

# 创建 hive 用户，若已经存在则无需再创建
mysql> create user 'hive' identified by 'hive';

# 赋予权限
mysql> grant all on *.* TO 'hive'@'%' identified by 'hive' with grant option;
mysql> grant all on *.* TO 'hive'@'localhost' identified by 'hive' with grant option;

# 刷新 MySQL 的系统权限相关表，否则会出现拒绝访问，还有一种方法是重新启动 mysql 服务器，来使新设置生效。
mysql> flush privileges;
```

（注意：如果是 root 第一次登录数据库，需要重新设置一下密码，所报异常信息如下：ERROR 1820 (HY000): You must SET PASSWORD before executing this statement）

**创建 hive 数据库**

使用 hive 用户登录，创建 hive 数据库：

```sql
mysql -uhive -phive -h hadoop
mysql> create database hive; # 若存在则无需再创建
mysql> show databases;
```

### 安装 Hive

配置本机主机名为 hadoop，sudo 时需要输入 shiyanlou 用户的密码。将 hadoop 添加到最后一行的末尾。

```bash
sudo vim /etc/hosts
# 将hadoop添加到最后一行的末尾，修改后类似：（使用 tab 键添加空格）
# 172.17.2.98 f738b9456777 hadoop
ping hadoop
```

使用如下命令启动 Hadoop

```bash
cd /app/hadoop-1.1.2/bin
./start-all.sh
jps # 查看启动的进程，确保 NameNode 和 DataNode 都有启动
```

**解压并移动 Hive 安装包**

可以到 Apache 基金 Hive 官网 `http://hive.apache.org/downloads.html`，选择镜像下载地址：`http://mirrors.cnnic.cn/apache/hive/` 下载一个稳定版本，如下图所示：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid276733labid1042timestamp1519716491988.png/wm)

也可以在 `/home/shiyanlou/install-pack` 目录中找到该安装包，解压该安装包并把该安装包复制到 `/app` 目录中（注：实验环境中的 hive 版本没有官网更新的高）。

```bash
cd /home/shiyanlou/install-pack
tar -xzf hive-0.12.0-bin.tar.gz
mv hive-0.12.0-bin /app/hive-0.12.0
```

**解压并移动 MySql 驱动包**

到 mysql 官网进入下载页面：http://dev.mysql.com/downloads/connector/j/，选择所需要的版本进行下载，这里下载的 zip 格式的文件。

也可以在 `/home/shiyanlou/install-pack` 目录中找到该安装包，解压该安装包并把该安装包复制到 `/app/lib` 目录中

```bash
cd /home/shiyanlou/install-pack
cp mysql-connector-java-5.1.22-bin.jar /app/hive-0.12.0/lib
```

**配置 /etc/profile 环境变量**

使用如下命令打开 `/etc/profile` 文件：

```bash
sudo vi /etc/profile
```

设置如下参数：

```text
export HIVE_HOME=/app/hive-0.12.0
export PATH=$PATH:$HIVE_HOME/bin
export CLASSPATH=$CLASSPATH:$HIVE_HOME/bin
```

使配置文件生效：

```bash
source /etc/profile
echo $PATH
```

**设置 hive-env.sh 配置文件**

进入 `hive-0.12.0/conf` 目录，复制 `hive-env.sh.templaete` 为 `hive-env.sh`：

```bash
cd /app/hive-0.12.0/conf
cp hive-env.sh.template hive-env.sh
sudo vi hive-env.sh
```

分别设置 `HADOOP_HOME` 和 `HIVE_CONF_DIR` 两个值：

```text
export HADOOP_HOME=/app/hadoop-1.1.2
export HIVE_CONF_DIR=/app/hive-0.12.0/conf
```

**设置 hive-site.xml 配置文件**

复制 `hive-default.xml.templaete` 为 `hive-site.xml`：

```bash
cd /app/hive-0.12.0/conf
cp hive-default.xml.template hive-site.xml
sudo vi hive-site.xml
```

**（1）加入配置项**

默认 metastore 在本地，添加配置改为非本地。

```text
<property>
  <name>hive.metastore.local</name>
  <value>false</value>
</property>
```

**（2）修改配置项**

hive 默认为 derby 数据库，需要把相关信息调整为 mysql 数据库。

```text
 <property>
   <name>hive.metastore.uris</name>
   <value>thrift://hadoop:9083</value>
   <description>Thrift URI for the remote metastore. ...</description>
 </property>
 <property>
   <name>javax.jdo.option.ConnectionURL</name>
   <value>jdbc:mysql://hadoop:3306/hive?=createDatabaseIfNotExist=true</value>
   <description>JDBC connect string for a JDBC metastore</description>
 </property>
 <property>
   <name>javax.jdo.option.ConnectionDriverName</name>
   <value>com.mysql.jdbc.Driver</value>
   <description>Driver class name for a JDBC metastore</description>
 </property>
 <property>
   <name>javax.jdo.option.ConnectionUserName</name>
   <value>hive</value>
   <description>username to use against metastore database</description>
 </property>
 <property>
   <name>javax.jdo.option.ConnectionPassword</name>
   <value>hive</value>
   <description>password to use against metastore database</description>
 </property>
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944084172.png/wm)

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944092960.png/wm)

**（3）订正错误项**

把 `hive.metastore.schema.verification` 配置项值修改为 false。

```text
 <property>
   <name>hive.metastore.schema.verification</name>
   <value>false</value>
    <desc....>
 </property>
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944116338.png/wm)

把 `/app/hive-0.12.0/conf/hive-site.xml` 文件中的大概在 2000 行位置左右，把原来的 `<value>auth</auth>` 修改为 `<value>auth</value>`，如下所示：

```text
 <property>
    <name>hive.server2.thrift.sasl.qop</name>
    <value>auth</value>
    ......
  </property>
```

还需要在环境中使用命令 `sudo service mysql start` 启动 mysql。

### 验证部署

**启动 metastore 和 hiveserver**

启动 MySQL 服务：

```bash
sudo service mysql start
```

在使用 hive 之前需要启动 metastore 和 hiveserver 服务，通过如下命令启用：

```bash
hive --service metastore &
hive --service hiveserver &
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944130232.png/wm)

通过 `jps` 命令可以看到两个进程运行在后台。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944136265.png/wm)

**在 hive 中操作**

登录 hive，在 hive 创建表并查看该表，命令如下：

```sql
hive
hive> create table test(a string, b int);
hive> show tables;
hive> desc test;
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944147986.png/wm)

登录 mysql，在 TBLS 表中查看新增 test 表：

```sql
mysql -uhive -phive
mysql> use hive;
mysql> select TBL_ID, CREATE_TIME, DB_ID, OWNER, TBL_NAME,TBL_TYPE from TBLS;
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944157594.png/wm)

## 问题解决

这一节我们将正式开始讲解实验，分步骤进行。

### 卸载旧的 mysql

**（1） 查找以前是否安装有 mysql**

使用命令查看是否已经安装过 mysql：

```bash
sudo rpm -qa | grep -i mysql
```

可以看到如下图的所示：

说明之前安装了：

```text
MySQL-client-5.6.21-1.el6.x86_64
MySQL-server-5.6.21-1.el6.x86_64
MySQL-devel-5.6.21-1.el6.x86_64
```

如果没有结果，可以进行跳到之前的 mysql 数据库安装步骤进行安装。

**（2） 停止 mysql 服务、删除之前安装的 mysql**

停止 mysql 服务、删除之前安装的 mysql 删除命令：rpm -ev –nodeps 包名

```bash
sudo rpm -ev MySQL-server-5.6.21-1.el6.x86_64
sudo rpm -ev MySQL-devel-5.6.21-1.el6.x86_64
sudo rpm -ev MySQL-client-5.6.21-1.el6.x86_64
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944181399.png/wm)

如果存在 CentOS 自带 `mysql-libs-5.6.21-1.el6.x86_64` 使用下面的命令卸载即可。

```bash
sudo rpm -ev --nodeps mysql-libs-5.6.21-1.el6.x86_64
```

**（3） 查找之前老版本 mysql 的目录并且删除老版本 mysql 的文件和库**

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944197444.png/wm)

```bash
sudo find / -name mysql
```

删除对应的 mysql 目录。

```bash
sudo rm -rf /usr/lib64/mysql
sudo rm -rf /var/lib/mysql
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944218976.png/wm)

**（4） 再次查找机器是否安装 mysql**

```bash
sudo rpm -qa | grep -i mysql
```

无结果，说明已经卸载彻底、接下来直接安装 mysql 即可

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944236587.png/wm)

### Hive 启动，报 CommandNeedRetryException 异常

启动 hive 时，出现 `CommandNeedRetryException` 异常，具体信息如下：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944253543.png/wm)

```text
Exception in thread "main" java.lang.NoClassDefFoundError:org/apache/hadoop/hive/ql/CommandNeedRetryException
        at java.lang.Class.forName0(Native Method)
        at java.lang.Class.forName(Class.java:270)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:149)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.ql.CommandNeedRetryException
        at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
        at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
        at java.security.AccessController.doPrivileged(Native Method)
        at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:425)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:358)
```

由于以前使用 hadoop 时，修改 hadoop-env.sh 的 HADOOP_CLASSPATH 配置项，由以前的：

```bash
export HADOOP_CLASSPATH=/app/hadoop-1.1.2/myclass
```

修改为：

```bash
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:/app/hadoop-1.1.2/myclass
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944272197.png/wm)

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944279419.png/wm)

### 在 Hive 中使用操作语言

启动 hive 后，使用 Hql 出现异常，需要启动 metastore 和 hiveserver。

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944379068.png/wm)

```text
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
```

在使用 hive 之前需要启动 metastore 和 hiveserver 服务，通过如下命令启用：

```bash
hive --service metastore &
hive --service hiveserver &
```

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944407865.png/wm)

启动用通过 jps 命令可以看到两个进程运行在后台：

![此处输入图片的描述](https://doc.shiyanlou.com/document-uid29778labid1042timestamp1433944504114.png/wm)
